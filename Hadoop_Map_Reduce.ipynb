{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hadoop Map-Reduce.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVpXQLGj3qeXKxeYmCj170",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhukarwakhare/Hadoop-Colab/blob/main/Hadoop_Map_Reduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWL9SUkdCzbY"
      },
      "source": [
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWDv0bYiDCPw"
      },
      "source": [
        "!tar -xzvf hadoop-3.3.1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t8o8NCJDDgj"
      },
      "source": [
        "#copy  hadoop file to user/local\n",
        "!cp -r hadoop-3.3.1/ /usr/local/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEhoM7opDdJq",
        "outputId": "605efe9a-f626-4096-8acb-da4f277525c3"
      },
      "source": [
        "#To find the default Java path\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-11-openjdk-amd64/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfL40AiADhNM"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU_lqA0PDkNN"
      },
      "source": [
        "#Running Hadoop\n",
        "!/usr/local/hadoop-3.3.1/bin/hadoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNYzkhlDv0E"
      },
      "source": [
        "# Download 20newsgroups dataset available at http://qwone.com/~jason/20Newsgroups."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkLW_bkYDyNg"
      },
      "source": [
        "!wget http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\n",
        "\n",
        "!tar -xzvf 20news-18828.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMRbacLoEfU1"
      },
      "source": [
        "# Hadoop Streaming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omaQpuk_EkMU"
      },
      "source": [
        "!find / -name 'hadoop-streaming*.jar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIU644BGEw1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183aaf03-35e2-406d-f567-c8bbf290b830"
      },
      "source": [
        "!chmod u+rwx /content/mapper.py\n",
        "!chmod u+rwx /content/reducer.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/content/mapper.py': No such file or directory\n",
            "chmod: cannot access '/content/reducer.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN6uvHM8GWdt"
      },
      "source": [
        "!/usr/local/hadoop-3.3.1/bin/hadoop jar /usr/local/hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar -input /content/20news-18828/alt.atheism/49960 -output /content/output -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8YpaceIGk8v",
        "outputId": "7afc3e69-ab37-4ed3-e6fc-678e6e784025"
      },
      "source": [
        "\n",
        "!ls /content/output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Bip_WwGpce"
      },
      "source": [
        "!cat /content/output/part-00000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3exh4wzXHYcS",
        "outputId": "a3db516b-7de1-45de-878a-29b2792592d8"
      },
      "source": [
        "!cat mapper.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"mapper.ipynb\n",
            "\n",
            "Automatically generated by Colaboratory.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1yCwGyMXJT2qt3_58aLOOiJXO0GIaPcJd\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "\n",
            "import sys\n",
            "import io\n",
            "import re\n",
            "import nltk\n",
            "nltk.download('stopwords',quiet=True)\n",
            "from nltk.corpus import stopwords\n",
            "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
            "\n",
            "stop_words = set(stopwords.words('english'))\n",
            "input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='latin1')\n",
            "for line in input_stream:\n",
            "  line = line.strip()\n",
            "  line = re.sub(r'[^\\w\\s]', '',line)\n",
            "  line = line.lower()\n",
            "  for x in line:\n",
            "    if x in punctuations:\n",
            "      line=line.replace(x, \" \") \n",
            "\n",
            "  words=line.split()\n",
            "  for word in words: \n",
            "    if word not in stop_words:\n",
            "      print('%s\\t%s' % (word, 1))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoZGAGn4NAkp",
        "outputId": "f86751f3-e861-4f3e-9a20-242c90b75116"
      },
      "source": [
        "!cat reducer.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"reducer.ipynb\n",
            "\n",
            "Automatically generated by Colaboratory.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1YzJ-vUsO5VYCyMrfPMow3s2IdxXkyQ0i\n",
            "\"\"\"\n",
            "\n",
            "from operator import itemgetter\n",
            "import sys\n",
            "\n",
            "current_word = None\n",
            "current_count = 0\n",
            "word = None\n",
            "\n",
            "# input comes from STDIN\n",
            "for line in sys.stdin:\n",
            "    # remove leading and trailing whitespace\n",
            "    line = line.strip()\n",
            "    line=line.lower()\n",
            "\n",
            "    # parse the input we got from mapper.py\n",
            "    word, count = line.split('\\t', 1)\n",
            "    try:\n",
            "      count = int(count)\n",
            "    except ValueError:\n",
            "      #count was not a number, so silently\n",
            "      #ignore/discard this line\n",
            "      continue\n",
            "\n",
            "    # this IF-switch only works because Hadoop sorts map output\n",
            "    # by key (here: word) before it is passed to the reducer\n",
            "    if current_word == word:\n",
            "        current_count += count\n",
            "    else:\n",
            "        if current_word:\n",
            "            # write result to STDOUT\n",
            "            print ('%s\\t%s' % (current_word, current_count))\n",
            "        current_count = count\n",
            "        current_word = word\n",
            "\n",
            "# do not forget to output the last word if needed!\n",
            "if current_word == word:\n",
            "    print( '%s\\t%s' % (current_word, current_count))\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}